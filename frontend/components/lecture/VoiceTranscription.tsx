'use client';

import React, { useState, useEffect, useRef, useCallback } from 'react';
import { useAuth } from '@/lib/context/AuthContext';

interface VoiceTranscriptionProps {
  lectureId: number;
  className?: string;
}

interface TranscriptionMessage {
  type: 'realtime' | 'fullSentence' | 'auth' | 'auth_response';
  text?: string;
  status?: string;
  message?: string;
  token?: string;
}

export default function VoiceTranscription({ lectureId, className = '' }: VoiceTranscriptionProps) {
  const { user } = useAuth();
  const [isConnected, setIsConnected] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [micAvailable, setMicAvailable] = useState(false);
  const [serverAvailable, setServerAvailable] = useState(false);
  const [fullSentences, setFullSentences] = useState<string[]>([]);
  const [realtimeText, setRealtimeText] = useState('');
  const [connectionStatus, setConnectionStatus] = useState('ğŸ–¥ï¸  ì„œë²„ì— ì—°ê²° ì¤‘...  ğŸ–¥ï¸');

  const socketRef = useRef<WebSocket | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const processorRef = useRef<ScriptProcessorNode | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const reconnectTimeoutRef = useRef<NodeJS.Timeout | null>(null);

  const connectToServer = useCallback(async () => {
    try {
      // í† í° ê°€ì ¸ì˜¤ê¸°
      const token = localStorage.getItem('access_token');
      if (!token) {
        console.error('ì¸ì¦ í† í°ì´ ì—†ìŠµë‹ˆë‹¤');
        return;
      }

      const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
      const host = window.location.hostname;
      const port = process.env.NODE_ENV === 'development' ? '8000' : window.location.port;
      
      // í† í°ì„ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ê°€ ì•„ë‹Œ ë©”ì‹œì§€ë¡œ ì „ì†¡í•˜ê¸° ìœ„í•´ URLì—ì„œ ì œê±°
      const wsUrl = `${protocol}//${host}:${port}/ws/stt/${lectureId}`;
      
      socketRef.current = new WebSocket(wsUrl);

      socketRef.current.onopen = () => {
        console.log('STT WebSocket ì—°ê²°ë¨, ì¸ì¦ ë©”ì‹œì§€ ì „ì†¡');
        
        // ì¸ì¦ ë©”ì‹œì§€ ì „ì†¡
        if (socketRef.current && socketRef.current.readyState === WebSocket.OPEN) {
          const authMessage = JSON.stringify({
            type: 'auth',
            token: token
          });
          socketRef.current.send(authMessage);
        }
        
        setIsConnected(true);
        setServerAvailable(true);
        updateConnectionStatus();
      };

      socketRef.current.onmessage = (event) => {
        try {
          const data: TranscriptionMessage = JSON.parse(event.data);
          
          // ì¸ì¦ ì‘ë‹µ ì²˜ë¦¬
          if (data.type === 'auth_response') {
            if (data.status === 'success') {
              console.log('STT ì¸ì¦ ì„±ê³µ:', data.message);
            } else {
              console.error('STT ì¸ì¦ ì‹¤íŒ¨:', data.message);
              setServerAvailable(false);
              updateConnectionStatus();
            }
            return;
          }
          
          if (data.type === 'realtime') {
            setRealtimeText(data.text);
          } else if (data.type === 'fullSentence') {
            setFullSentences(prev => [...prev, data.text]);
            setRealtimeText(''); // ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
          }
        } catch (error) {
          console.error('ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜:', error);
        }
      };

      socketRef.current.onclose = (event) => {
        console.log('STT WebSocket ì—°ê²° ëŠê¹€', {
          code: event.code,
          reason: event.reason || 'ì´ìœ  ì—†ìŒ',
          wasClean: event.wasClean
        });
        
        setIsConnected(false);
        setServerAvailable(false);
        updateConnectionStatus();
        
        // 5ì´ˆ í›„ ì¬ì—°ê²° ì‹œë„
        if (reconnectTimeoutRef.current) {
          clearTimeout(reconnectTimeoutRef.current);
        }
        reconnectTimeoutRef.current = setTimeout(() => {
          connectToServer();
        }, 5000);
      };

      socketRef.current.onerror = (error) => {
        console.error('STT WebSocket ì˜¤ë¥˜:', error);
        setServerAvailable(false);
        updateConnectionStatus();
      };

    } catch (error) {
      console.error('WebSocket ì—°ê²° ì˜¤ë¥˜:', error);
      setServerAvailable(false);
      updateConnectionStatus();
    }
  }, [lectureId]);

  const updateConnectionStatus = useCallback(() => {
    if (!micAvailable) {
      setConnectionStatus('ğŸ¤  ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”  ğŸ¤');
    } else if (!serverAvailable) {
      setConnectionStatus('ğŸ–¥ï¸  ì„œë²„ì— ì—°ê²° ì¤‘...  ğŸ–¥ï¸');
    } else {
      setConnectionStatus('ğŸ‘„  ë§ì”€í•´ì£¼ì„¸ìš”  ğŸ‘„');
    }
  }, [micAvailable, serverAvailable]);

  const startRecording = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 16000, // RealtimeSTT ì„œë²„ê°€ ì˜ˆìƒí•˜ëŠ” ìƒ˜í”Œë ˆì´íŠ¸
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        } 
      });
      
      streamRef.current = stream;
      setMicAvailable(true);
      setIsRecording(true);
      updateConnectionStatus();

      // AudioContext ìƒì„± - 16kHzë¡œ ì„¤ì •
      audioContextRef.current = new AudioContext({ sampleRate: 16000 });
      const source = audioContextRef.current.createMediaStreamSource(stream);
      
      // ScriptProcessorNode ìƒì„± (RealtimeSTT ì˜ˆì œì— ë§ê²Œ ë²„í¼ í¬ê¸° ì¡°ì •)
      processorRef.current = audioContextRef.current.createScriptProcessor(4096, 1, 1);
      
      source.connect(processorRef.current);
      processorRef.current.connect(audioContextRef.current.destination);

      processorRef.current.onaudioprocess = (e) => {
        if (!socketRef.current || socketRef.current.readyState !== WebSocket.OPEN) {
          return;
        }

        const inputData = e.inputBuffer.getChannelData(0);
        const outputData = new Int16Array(inputData.length);

        // Float32Arrayë¥¼ 16-bit PCMìœ¼ë¡œ ë³€í™˜
        for (let i = 0; i < inputData.length; i++) {
          outputData[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
        }

        // ë©”íƒ€ë°ì´í„° ìƒì„± - RealtimeSTT ì„œë²„ê°€ ì˜ˆìƒí•˜ëŠ” í˜•ì‹ìœ¼ë¡œ
        const metadata = JSON.stringify({ 
          sampleRate: audioContextRef.current?.sampleRate || 16000 
        });
        const metadataBytes = new TextEncoder().encode(metadata);
        
        // ë©”íƒ€ë°ì´í„° ê¸¸ì´ë¥¼ 4ë°”ì´íŠ¸ë¡œ ì¸ì½”ë”©
        const metadataLength = new ArrayBuffer(4);
        const metadataLengthView = new DataView(metadataLength);
        metadataLengthView.setInt32(0, metadataBytes.byteLength, true); // little-endian
        
        // ë©”íƒ€ë°ì´í„° ê¸¸ì´ + ë©”íƒ€ë°ì´í„° + ì˜¤ë””ì˜¤ ë°ì´í„° ê²°í•©
        const combinedData = new Blob([metadataLength, metadataBytes, outputData.buffer]);
        
        socketRef.current.send(combinedData);
      };

    } catch (error) {
      console.error('ë§ˆì´í¬ ì ‘ê·¼ ì˜¤ë¥˜:', error);
      setConnectionStatus('ğŸ¤  ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤  ğŸ¤');
      setMicAvailable(false);
    }
  }, [updateConnectionStatus]);

  const stopRecording = useCallback(() => {
    setIsRecording(false);
    
    if (processorRef.current) {
      processorRef.current.disconnect();
      processorRef.current = null;
    }
    
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }
    
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    
    updateConnectionStatus();
  }, [updateConnectionStatus]);

  const clearTranscription = useCallback(() => {
    setFullSentences([]);
    setRealtimeText('');
  }, []);

  // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ ì„œë²„ ì—°ê²°
  useEffect(() => {
    connectToServer();
    
    return () => {
      if (reconnectTimeoutRef.current) {
        clearTimeout(reconnectTimeoutRef.current);
      }
      if (socketRef.current) {
        socketRef.current.close();
      }
      stopRecording();
    };
  }, [connectToServer, stopRecording]);

  // ì—°ê²° ìƒíƒœ ì—…ë°ì´íŠ¸
  useEffect(() => {
    updateConnectionStatus();
  }, [updateConnectionStatus]);

  const displayedText = fullSentences
    .map((sentence, index) => (
      <span 
        key={index} 
        className={index % 2 === 0 ? 'text-yellow-600' : 'text-cyan-600'}
      >
        {sentence}{' '}
      </span>
    ))
    .concat([
      <span key="realtime" className="text-gray-600">
        {realtimeText}
      </span>
    ]);

  return (
    <div className={`bg-white rounded-lg shadow-lg p-6 ${className}`}>
      <div className="flex justify-between items-center mb-4">
        <h3 className="text-lg font-semibold text-gray-800">ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹</h3>
        <div className="flex gap-2">
          <button
            onClick={isRecording ? stopRecording : startRecording}
            disabled={!serverAvailable}
            className={`px-4 py-2 rounded-lg font-medium transition-colors ${
              isRecording
                ? 'bg-red-600 hover:bg-red-700 text-white'
                : 'bg-blue-600 hover:bg-blue-700 text-white disabled:bg-gray-400'
            }`}
          >
            {isRecording ? 'ğŸ”´ ì¤‘ì§€' : 'ğŸ¤ ì‹œì‘'}
          </button>
          <button
            onClick={clearTranscription}
            className="px-4 py-2 bg-gray-600 hover:bg-gray-700 text-white rounded-lg font-medium transition-colors"
          >
            ì§€ìš°ê¸°
          </button>
        </div>
      </div>

      <div className="space-y-4">
        {/* ì—°ê²° ìƒíƒœ */}
        <div className="text-center py-2 px-4 bg-gray-100 rounded-lg">
          <span className="text-sm font-medium">{connectionStatus}</span>
        </div>

        {/* ìƒíƒœ í‘œì‹œê¸° */}
        <div className="flex justify-center space-x-4 text-sm">
          <div className="flex items-center gap-2">
            <div className={`w-3 h-3 rounded-full ${isConnected ? 'bg-green-500' : 'bg-red-500'}`}></div>
            <span>ì„œë²„ ì—°ê²°</span>
          </div>
          <div className="flex items-center gap-2">
            <div className={`w-3 h-3 rounded-full ${micAvailable ? 'bg-green-500' : 'bg-red-500'}`}></div>
            <span>ë§ˆì´í¬</span>
          </div>
          <div className="flex items-center gap-2">
            <div className={`w-3 h-3 rounded-full ${isRecording ? 'bg-green-500 animate-pulse' : 'bg-gray-500'}`}></div>
            <span>ë…¹ìŒì¤‘</span>
          </div>
        </div>

        {/* ì „ì‚¬ ê²°ê³¼ */}
        <div className="min-h-32 max-h-64 overflow-y-auto p-4 bg-gray-50 rounded-lg border">
          <div className="text-sm leading-relaxed">
            {displayedText.length === 1 && !fullSentences.length && !realtimeText ? (
              <span className="text-gray-400">ìŒì„± ì¸ì‹ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤...</span>
            ) : (
              displayedText
            )}
          </div>
        </div>

        {/* í†µê³„ */}
        {fullSentences.length > 0 && (
          <div className="text-xs text-gray-500 text-center">
            ì´ {fullSentences.length}ê°œ ë¬¸ì¥ ì¸ì‹ë¨
          </div>
        )}
      </div>
    </div>
  );
} 